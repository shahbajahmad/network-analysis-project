# Spark Configuration File

# Cluster mode: local, yarn, or standalone
master: "spark://spark-master:7077"  # Replace with the actual master URL or use "local[*]" for local mode

# Application name
app_name: "NetworkAnalysisJob"

# Spark executor memory allocation
executor_memory: "2g"

# Number of executor cores
executor_cores: 2

# Spark driver memory allocation
driver_memory: "1g"

# Spark job configurations
configurations:
  spark.sql.shuffle.partitions: 4       # Number of shuffle partitions
  spark.default.parallelism: 4          # Default parallelism level
  spark.serializer: "org.apache.spark.serializer.KryoSerializer"  # Serializer for better performance
  spark.sql.autoBroadcastJoinThreshold: -1   # Disable auto broadcasting for large joins

# Application-specific settings (if needed)
application_settings:
  input_path: "hdfs://namenode:9000/data/network_devices.json"  # Input data path in HDFS
  output_path: "hdfs://namenode:9000/output/network_analysis"   # Output data path in HDFS
  checkpoint_dir: "hdfs://namenode:9000/checkpoints"            # Directory for checkpoints
