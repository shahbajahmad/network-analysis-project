version: '3.8'

services:
  # Zookeeper for Kafka
  zookeeper:
    image: wurstmeister/zookeeper:latest
    container_name: zookeeper
    ports:
      - "2181:2181"
  
  # Kafka for data ingestion
  kafka:
    image: wurstmeister/kafka:latest
    container_name: kafka
    ports:
      - "9092:9092"
    environment:
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092
    depends_on:
      - zookeeper
  
  # Hadoop Namenode for data storage
  hadoop-namenode:
    build:
      context: ./storage/hadoop
    container_name: hadoop-namenode
    ports:
      - "50070:50070"
      - "9000:9000"
    environment:
      - CLUSTER_NAME=hadoop-cluster
    volumes:
      - hadoop-namenode-data:/hadoop/dfs/name

  # Hadoop Datanode for data storage
  hadoop-datanode:
    build:
      context: ./storage/hadoop
    container_name: hadoop-datanode
    ports:
      - "50075:50075"
    environment:
      - CLUSTER_NAME=hadoop-cluster
    volumes:
      - hadoop-datanode-data:/hadoop/dfs/data
    depends_on:
      - hadoop-namenode

  # Spark master node for data processing
  spark-master:
    build:
      context: ./processing/spark
    container_name: spark-master
    ports:
      - "8080:8080"
    environment:
      - SPARK_MODE=master
      - SPARK_MASTER_URL=spark://spark-master:7077
    depends_on:
      - hadoop-namenode

  # Spark worker node for data processing
  spark-worker:
    build:
      context: ./processing/spark
    container_name: spark-worker
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-master:7077
    depends_on:
      - spark-master

  # Flask API for data delivery
  flask-api:
    build:
      context: ./delivery/api
    container_name: flask-api
    ports:
      - "5000:5000"
    depends_on:
      - spark-master

  # Airflow for orchestration
  airflow:
    build:
      context: ./orchestration/airflow
    container_name: airflow
    ports:
      - "8081:8081"
    environment:
      - AIRFLOW__CORE__EXECUTOR=LocalExecutor
    volumes:
      - ./orchestration/airflow/dags:/opt/airflow/dags
    depends_on:
      - kafka
      - spark-master
      - hadoop-namenode

  # Prometheus for monitoring
  prometheus:
    image: prom/prometheus:latest
    container_name: prometheus
    ports:
      - "9090:9090"
    volumes:
      - ./monitoring/prometheus/prometheus.yml:/etc/prometheus/prometheus.yml

  # Grafana for visualization
  grafana:
    image: grafana/grafana:latest
    container_name: grafana
    ports:
      - "3000:3000"
    volumes:
      - ./monitoring/grafana:/var/lib/grafana
    depends_on:
      - prometheus

volumes:
  hadoop-namenode-data:
    driver: local
  hadoop-datanode-data:
    driver: local
